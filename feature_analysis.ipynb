{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\School\\Grad\\learning-social-circles\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from utility_funcs import readcirclefile, read_nodeadjlist, cost_function\n",
    "import os\n",
    "import sklearn.cluster\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pathlib import Path\n",
    "from node2vec import Node2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import deepwalk\n",
    "\n",
    "\n",
    "root_dir = Path.cwd().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfeaturelist(filename):\n",
    "    \"\"\"\n",
    "    reads a featurelist file and returns a list of the feature names\n",
    "    \"\"\"\n",
    "    with open(filename) as f:\n",
    "        out = []        # list of feature names\n",
    "        for line in f:\n",
    "            out.append(line.strip())\n",
    "        return sorted(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['birthday', 'education;classes;description', 'education;classes;from;id', 'education;classes;from;name', 'education;classes;id', 'education;classes;name', 'education;classes;with;id', 'education;classes;with;name', 'education;concentration;id', 'education;concentration;name', 'education;degree;id', 'education;degree;name', 'education;school;id', 'education;school;name', 'education;type', 'education;with;id', 'education;with;name', 'education;year;id', 'education;year;name', 'first_name', 'gender', 'hometown;id', 'hometown;name', 'id', 'languages;id', 'languages;name', 'last_name', 'locale', 'location', 'location;id', 'location;name', 'middle_name', 'name', 'political', 'religion', 'work;description', 'work;employer;id', 'work;employer;name', 'work;end_date', 'work;from;id', 'work;from;name', 'work;location;id', 'work;location;name', 'work;position;id', 'work;position;name', 'work;projects;description', 'work;projects;end_date', 'work;projects;from;id', 'work;projects;from;name', 'work;projects;id', 'work;projects;name', 'work;projects;start_date', 'work;projects;with;id', 'work;projects;with;name', 'work;start_date', 'work;with;id', 'work;with;name']\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "features = readfeaturelist(root_dir / 'featureList.txt')\n",
    "print( features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfeatures(featurefile):\n",
    "    \"\"\"\n",
    "    reads a featurefile consisting of userid feature;value feature;value\n",
    "    returns a list where index is user id, elements are dictionaries \n",
    "    of features as keys pointing to list of values maybe should be sets\n",
    "    \"\"\"\n",
    "    with open(featurefile) as f:\n",
    "        out = [] \n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            profile = {}  # empty profile for the user\n",
    "            for tok in tokens[1:]:\n",
    "                feature,val = tok.rsplit(';',1)\n",
    "                val = int(val)\n",
    "                if feature not in profile:\n",
    "                    profile[feature]=set([val])\n",
    "                else:\n",
    "                    profile[feature].add(val)\n",
    "            out.append( profile )\n",
    "        for i in range(len(out)):\n",
    "            assert out[i]['id'] == set([i])  # check that each line was read and placed in the correct place in the list\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_profile_dict_to_vector(profile,features):\n",
    "    out = []\n",
    "    for feature in features:\n",
    "        if feature in profile:\n",
    "            out.append(profile[feature])\n",
    "        else:\n",
    "            out.append(set())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_vector(profile1,profile2):\n",
    "    return [len(x.intersection(y)) for x,y in zip(profile1,profile2)]\n",
    "     \n",
    "\n",
    "def generate_feature_matrix(profiles_dict,ego,G):\n",
    "    return [match_vector(profiles_dict[ego], profiles_dict[g]) for g in G.nodes()]\n",
    "     \n",
    "\n",
    "def generate_class_matrix(G,true_circles):\n",
    "    return dict(zip(true_circles.keys(),[[int(g in circle) for g in G.nodes()] for circle in true_circles.values()]))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_dict = readfeatures('features.txt')\n",
    "\n",
    "profile_matrix = [convert_profile_dict_to_vector(profile,features) for profile in profiles_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ego = 345\n",
    "true_circles = readcirclefile('./Training/'+str(ego)+'.circles')\n",
    "G = read_nodeadjlist('./egonets/'+str(ego)+'.egonet')\n",
    "print('Total friends:', len(G.nodes()))\n",
    "class_matrix = generate_class_matrix(G,true_circles)\n",
    "feature_matrix = generate_feature_matrix(profile_matrix,ego,G)\n",
    "\n",
    "for label,circle in class_matrix.items():\n",
    "    print('Training Ego:', ego,'Circle:',label,'...')\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    forest = forest.fit( feature_matrix, circle )\n",
    "    important_features = sorted(zip(features,forest.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "    importance_scores = [val for key,val in important_features]\n",
    "    importance_labels = [key for key,val in important_features]\n",
    "    ind = range(len(importance_scores))\n",
    "    plt.bar(ind, forest.feature_importances_)\n",
    "    plt.axis([min(ind), max(ind), 0, 0.7])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(true_circles.keys(),[[int(g in circle) for g in G.nodes()] for circle in true_circles.values()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_circles = readcirclefile('./Training/'+str(ego)+'.circles')\n",
    "G = read_nodeadjlist('./egonets/'+str(ego)+'.egonet')\n",
    "print('Total friends:', len(G.nodes()))\n",
    "class_matrix = generate_class_matrix(G,true_circles)\n",
    "feature_matrix = generate_feature_matrix(profile_matrix,ego,G)\n",
    "\n",
    "for label,circle in class_matrix.items():\n",
    "    print('Training Ego:', ego,'Circle:',label,'...')\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    forest = forest.fit( feature_matrix, circle )\n",
    "    important_features = sorted(zip(features,forest.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "    importance_scores = [val for key,val in important_features]\n",
    "    importance_labels = [key for key,val in important_features]\n",
    "    ind = range(len(importance_scores))\n",
    "    plt.bar(ind, forest.feature_importances_)\n",
    "    plt.axis([min(ind), max(ind), 0, 0.7])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingfiles = os.listdir('./Training/')\n",
    "\n",
    "df_labels = ['Ego','Circle']+features\n",
    "characteristic_profiles = []\n",
    "\n",
    "for item in trainingfiles:\n",
    "    ego = int((item.split('.')[0]))\n",
    "    true_circles = readcirclefile('./Training/'+item)\n",
    "    G = read_nodeadjlist('./egonets/'+str(ego)+'.egonet')\n",
    "    class_matrix = generate_class_matrix(G,true_circles)\n",
    "    feature_matrix = generate_feature_matrix(profile_matrix,ego,G)\n",
    "    \n",
    "    for label,circle in class_matrix.items():\n",
    "        print('Training Ego:', ego,'Circle:',label,'...')\n",
    "        forest = RandomForestClassifier(n_estimators=100)\n",
    "        forest = forest.fit( feature_matrix, circle )\n",
    "        characteristic_profiles.append([ego]+[label]+list(forest.feature_importances_))\n",
    "\n",
    "df = pd.DataFrame(data=characteristic_profiles,columns=df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean().sort_values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('characterist_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df[df.min(axis=1)>=0]\n",
    "df_neg = df[df.min(axis=1)<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_mean = df_pos.mean()\n",
    "df_pos_mean.sort_values(ascending=False)\n",
    "rand_chance = (len(df_pos_mean)-2)\n",
    "df_pos_mean[df_pos_mean.gt(1./(rand_chance))]*rand_chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_mean*rand_chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos.mean()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 11812/11812 [00:03<00:00, 3046.68it/s]\n",
      "e:\\School\\Grad\\learning-social-circles\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1076: UserWarning: On Windows, max_workers cannot exceed 61 due to limitations of the operating system.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 14829 is out of bounds for axis 0 with size 11812",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m train_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[1;32m---> 66\u001b[0m     combined_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m]\u001b[49m, [specific_profile[user_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m], specific_profile[user_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m], specific_profile[user_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m]]])\n\u001b[0;32m     67\u001b[0m     user_combined_features\u001b[38;5;241m.\u001b[39mappend(combined_features)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Add positive pairs (edges)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 14829 is out of bounds for axis 0 with size 11812"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "profiles_dict = readfeatures('features.txt')\n",
    "\n",
    "specific_profile = {}\n",
    "labels = ['locale', 'education;school;name', 'education;school;id', 'last_name']\n",
    "for profile in profiles_dict:\n",
    "    id = profile['id'].pop()\n",
    "    inisde_dict = {}\n",
    "    for spec in labels:\n",
    "        inisde_dict[spec] = profile.get(spec, set({-1})).pop()\n",
    "    specific_profile[id] = inisde_dict\n",
    "\n",
    "\n",
    "profile_matrix = [convert_profile_dict_to_vector(profile,features) for profile in profiles_dict]\n",
    "\n",
    "# The most impactful features are as follows:\n",
    "# work;employer;id                     0.019194\n",
    "# work;employer;name                   0.026036\n",
    "# hometown;name                        0.026805\n",
    "# hometown;id                          0.028106\n",
    "# work;start_date                      0.028649\n",
    "# location;id                          0.031029\n",
    "# location;name                        0.031354\n",
    "# education;year;id                    0.033277\n",
    "# education;year;name                  0.034244\n",
    "# last_name                            0.034566\n",
    "# education;school;id                  0.052966\n",
    "# education;school;name                0.056747\n",
    "# locale                               0.133719\n",
    "# gender                               0.173660\n",
    "# education;type                       0.184633\n",
    "\n",
    "# [print(profile['education;type']) for profile in profiles_dict]\n",
    "trainingfiles = os.listdir('./Training/')\n",
    "\n",
    "edges = []\n",
    "for item in trainingfiles:\n",
    "    ego = int((item.split('.')[0]))\n",
    "    true_circles = readcirclefile('./Training/'+item)\n",
    "    # print(true_circles)\n",
    "    for key in true_circles.keys():\n",
    "        values = true_circles[key]\n",
    "        for value in values:\n",
    "            edges.append((key, value))\n",
    "\n",
    "\n",
    "# Initialize an undirected graph using NetworkX\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Apply DeepWalk to generate embeddings for each node (user)\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=50, num_walks=200, workers=1000)\n",
    "model = node2vec.fit()\n",
    "\n",
    "# Extract embeddings for each node (user)\n",
    "embeddings = np.array([model.wv[str(i)] for i in G.nodes()])\n",
    "edges = list(G.edges())\n",
    "non_edges = list(nx.non_edges(G))\n",
    "\n",
    "user_combined_features = []\n",
    "train_data = []\n",
    "\n",
    "for user_id in G.nodes():\n",
    "    combined_features = np.concatenate([embeddings[user_id], [specific_profile[user_id]['locale'], specific_profile[user_id]['locale'], specific_profile[user_id]['locale']]])\n",
    "    user_combined_features.append(combined_features)\n",
    "\n",
    "# Add positive pairs (edges)\n",
    "for edge in edges:\n",
    "    user1, user2 = edge\n",
    "    label = 1  # They are friends\n",
    "    features = np.concatenate([user_combined_features[user1], user_combined_features[user2]])\n",
    "    train_data.append((features, label))\n",
    "\n",
    "# Add negative pairs (non-edges)\n",
    "for non_edge in non_edges:\n",
    "    user1, user2 = non_edge\n",
    "    label = 0  # They are not friends\n",
    "    features = np.concatenate([user_combined_features[user1], user_combined_features[user2]])\n",
    "    train_data.append((features, label))\n",
    "\n",
    "# Split data into features and labels\n",
    "X = np.array([data[0] for data in train_data])\n",
    "y = np.array([data[1] for data in train_data])\n",
    "\n",
    "# Train a classifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Classifier Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predicting friendship for a pair of users\n",
    "prediction = clf.predict([np.concatenate([user_combined_features[user1], user_combined_features[user2]])])\n",
    "print(f\"Are users {user1} and {user2} friends? {'Yes' if prediction[0] == 1 else 'No'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
